{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pathlib import Path\n",
    "import shared_functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model & file name\n",
    "model_name = 'MultiModalModel_1IMG_16'\n",
    "file_name = 'property-sales_new-york-city_2022_pre-processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for exports\n",
    "Path(f'../models/{model_name}').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subset keys as list\n",
    "subset_keys = pd.read_csv(f'../data/processed/subset_keys.csv').squeeze().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subset index as series\n",
    "subset_index = pd.read_csv(f'../data/processed/subset_index.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device type: CPU\n"
     ]
    }
   ],
   "source": [
    "# Use GPU when possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "print(f'Device type: {device.upper()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    'data': f'../data/processed/{file_name}.parquet',\n",
    "    'target_name': 'sale_price',\n",
    "    'to_drop': 'sale_price_adj',\n",
    "    'image_directory': '../data/raw/satellite-images_new-york-city_2022_640x640_16/',\n",
    "    'image_transformation': transforms.Compose([\n",
    "        transforms.CenterCrop((600, 600)), # crop image borders by margin of 20px to remove text from 640x640\n",
    "        transforms.Resize((299, 299)), # resize image to 299x299\n",
    "        transforms.ToTensor(),  # convert image to PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # noarmlize based on ImageNet data\n",
    "        ]),\n",
    "    'subset_index': '../data/processed/subset_index.csv',\n",
    "    'input_scaler': StandardScaler(),\n",
    "    'target_scaler': None,\n",
    "    'categorical_encoder': TargetEncoder(),\n",
    "    'numerical_imputer': SimpleImputer(missing_values=pd.NA, strategy='mean'),\n",
    "    'data_overview': f'../data/processed/{file_name}_data-overview.csv'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate datasets\n",
    "subsets = {subset_key: sf.MultiModalDataset(**dataset_params, subset=subset_key) for subset_key in subset_keys}\n",
    "dataset = sf.MultiModalDataset(**dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class MLPModel_Dropout(nn.Module):\n",
    "    # Define model components\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define text model\n",
    "        self.TextModel = nn.Sequential(\n",
    "            nn.Linear(dataset.X_text.shape[1], 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.4),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.4),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.4),\n",
    "            nn.Linear(32, 1)\n",
    "            )\n",
    "\n",
    "    # Define forward pass\n",
    "    def forward(self, X_text):\n",
    "        y = self.TextModel(X_text)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class MultiModalModel_1IMG(nn.Module):\n",
    "    # Define model components\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define text model\n",
    "        self.TextModel = MLPModel_Dropout()\n",
    "        \n",
    "        # Load optimal weights\n",
    "        self.TextModel.load_state_dict(torch.load('../models/MLPModel_Dropout/state_dict.pt'))\n",
    "        for parameter in self.TextModel.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        \n",
    "        # Define image model\n",
    "        self.ImageModel = inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "        self.ImageModel.aux_logits = False\n",
    "        for parameter in self.ImageModel.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        self.ImageModel.fc = nn.Sequential(\n",
    "            nn.Linear(self.ImageModel.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 1)\n",
    "            )\n",
    "\n",
    "        # Define linear layer for output\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "\n",
    "        # Define acitvation function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    # Define forward pass\n",
    "    def forward(self, X_text, X_image):\n",
    "        X_text = self.relu(self.TextModel(X_text))\n",
    "        X_image = self.relu(self.ImageModel(X_image))\n",
    "        y = self.linear(torch.cat((X_text, X_image), dim=1))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = MultiModalModel_1IMG().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model paramters: 26199309\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of model parameters\n",
    "n_params = sum(parameter.numel() for parameter in model.parameters())\n",
    "print(f'# model paramters: {n_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not train if already trained\n",
    "if Path(f'../models/{model_name}/state_dict.pt').is_file() and Path(f'../models/{model_name}/history.csv').is_file():\n",
    "    # Load optimal weights and history\n",
    "    model.load_state_dict(torch.load(f'../models/{model_name}/state_dict.pt', map_location='cpu'))\n",
    "    history = pd.read_csv(f'../models/{model_name}/history.csv', index_col=0)\n",
    "    print('Skipping training and loading optimal weights from previous training!')\n",
    "else:\n",
    "    # Train model\n",
    "    model, history = sf.train_model(\n",
    "        model=model,\n",
    "        dataset_train=subsets['train'],\n",
    "        dataset_val=subsets['val'],\n",
    "\n",
    "        # Define loss & optimizer\n",
    "        loss_function=nn.MSELoss().to(device),\n",
    "        optimizer=optim.Adam(params=model.parameters(), lr=.01),\n",
    "\n",
    "        # Define computing device\n",
    "        device=device,\n",
    "\n",
    "        # Define training parameters\n",
    "        epochs=25,\n",
    "        patience=25,\n",
    "        delta=0,\n",
    "        batch_size=1024,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "\n",
    "        # Define save locations\n",
    "        save_state_dict_as=f'../models/{model_name}/state_dict.pt',\n",
    "        save_history_as=f'../models/{model_name}/history.csv'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model predictions\n",
    "predictions = sf.get_predictions(model, dataset, subset_index, device, save_as=f'../models/{model_name}/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance metrics\n",
    "metrics = sf.get_metrics(predictions, subset_keys, save_as=f'../models/{model_name}/perf_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "sf.plot_history(history, save_as=f'../models/{model_name}/history.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actuals\n",
    "sf.plot_pred_vs_actual(predictions, save_as=f'../models/{model_name}/predictions_vs_actuals.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
